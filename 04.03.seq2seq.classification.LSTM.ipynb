{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence to Sequence Classification by RNN\n",
    "\n",
    "- Creating the **data pipeline** with `tf.data`\n",
    "- Preprocessing word sequences (variable input sequence length) using `padding technique` by `user function (pad_seq)`\n",
    "- Using `tf.nn.embedding_lookup` for getting vector of tokens (eg. word, character)\n",
    "- Training **many to many classification** with `tf.contrib.seq2seq.sequence_loss`\n",
    "- Masking unvalid token with `tf.sequence_mask`\n",
    "- Creating the model as **Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "rnn = tf.contrib.rnn\n",
    "\n",
    "sess_config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare example data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [['I', 'feel', 'hungry'],\n",
    "             ['You', 'are', 'a', 'genius'],\n",
    "             ['tensorflow', 'is', 'very', 'difficult'],\n",
    "             ['tensorflow', 'is', 'a', 'framework', 'for', 'deep', 'learning'],\n",
    "             ['tensorflow', 'is', 'very', 'fast', 'changing']]\n",
    "pos = [['pronoun', 'verb', 'adjective'],\n",
    "       ['pronoun', 'verb', 'preposition', 'noun'],\n",
    "       ['noun', 'verb', 'adverb', 'adjective'],\n",
    "       ['noun', 'verb', 'determiner', 'noun', 'preposition', 'adjective', 'noun'],\n",
    "       ['noun', 'verb', 'adverb', 'adjective', 'verb']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<pad>': 0,\n",
       " 'I': 1,\n",
       " 'a': 2,\n",
       " 'changing': 3,\n",
       " 'deep': 4,\n",
       " 'difficult': 5,\n",
       " 'fast': 6,\n",
       " 'feel': 7,\n",
       " 'for': 8,\n",
       " 'framework': 9,\n",
       " 'hungry': 10,\n",
       " 'is': 11,\n",
       " 'learning': 12,\n",
       " 'tensorflow': 13,\n",
       " 'very': 14}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word dictionary\n",
    "bag_of_words = []\n",
    "for sentence in sentences:\n",
    "  bag_of_words += sentence\n",
    "bag_of_words = list(set(bag_of_words))\n",
    "bag_of_words.sort()\n",
    "bag_of_words = ['<pad>'] + bag_of_words\n",
    "\n",
    "word2idx = {word : idx for idx, word in enumerate(bag_of_words)} # word to index\n",
    "idx2word = [word for word in bag_of_words] # index to word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad>',\n",
       " 'I',\n",
       " 'a',\n",
       " 'changing',\n",
       " 'deep',\n",
       " 'difficult',\n",
       " 'fast',\n",
       " 'feel',\n",
       " 'for',\n",
       " 'framework',\n",
       " 'hungry',\n",
       " 'is',\n",
       " 'learning',\n",
       " 'tensorflow',\n",
       " 'very']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(\"word2idx: {}\".format(word2idx))\n",
    "word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"idx2word: {}\".format(idx2word))\n",
    "idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag_of_pos: ['<pad>', 'adjective', 'adverb', 'determiner', 'noun', 'preposition', 'pronoun', 'verb']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'<pad>': 0,\n",
       " 'adjective': 1,\n",
       " 'adverb': 2,\n",
       " 'determiner': 3,\n",
       " 'noun': 4,\n",
       " 'preposition': 5,\n",
       " 'pronoun': 6,\n",
       " 'verb': 7}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pos dictionary\n",
    "bag_of_pos = []\n",
    "for item in pos:\n",
    "  bag_of_pos += item\n",
    "bag_of_pos = list(set(bag_of_pos))\n",
    "bag_of_pos.sort()\n",
    "bag_of_pos = ['<pad>'] + bag_of_pos\n",
    "print(\"bag_of_pos: {}\".format(bag_of_pos))\n",
    "\n",
    "pos2idx = {pos : idx for idx, pos in enumerate(bag_of_pos)} # pos to index\n",
    "idx2pos = [pos for pos in bag_of_pos] # index to pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad>',\n",
       " 'adjective',\n",
       " 'adverb',\n",
       " 'determiner',\n",
       " 'noun',\n",
       " 'preposition',\n",
       " 'pronoun',\n",
       " 'verb']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(\"pos2idx: {}\".format(pos2idx))\n",
    "pos2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"idx2pos: {}\".format(idx2pos))\n",
    "idx2pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create pad_seq function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_seq(sequences, max_length, dic):\n",
    "  \"\"\"Padding sequences\n",
    "  Padding a special charcter '<pad>' from the end of sentence to max_length\n",
    "  \n",
    "  Args:\n",
    "    sequences (list of characters): input data\n",
    "    max_length (int): max length for padding\n",
    "    dic (dictionary): char to index\n",
    "  \n",
    "  Returns:\n",
    "    seq_indices (2-rank np.array): \n",
    "    seq_length (1-rank np.array): sequence lengthes of all data\n",
    "  \"\"\"\n",
    "  seq_length, seq_indices = [], []\n",
    "  for sequence in sequences:\n",
    "    seq_length.append(len(sequence))\n",
    "    seq_idx = [dic.get(char) for char in sequence]\n",
    "    seq_idx += (max_length - len(seq_idx)) * [dic.get('<pad>')] # 0 is idx of meaningless token \"<pad>\"\n",
    "    seq_indices.append(seq_idx)\n",
    "  return np.array(seq_indices), np.array(seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 10\n",
    "X_indices, X_length = pad_seq(sequences=sentences, max_length=max_length, dic=word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_indices\n",
      "[[ 1  7 10  0  0  0  0  0  0  0]\n",
      " [13 11 14  5  0  0  0  0  0  0]\n",
      " [13 11  2  9  8  4 12  0  0  0]\n",
      " [13 11 14  6  3  0  0  0  0  0]]\n",
      "X_length\n",
      "[3 4 7 5]\n"
     ]
    }
   ],
   "source": [
    "print(\"X_indices\")\n",
    "print(X_indices)\n",
    "print(\"X_length\")\n",
    "print(X_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['pronoun' 'verb' 'adjective' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>'\n",
      "  '<pad>' '<pad>']\n",
      " ['noun' 'verb' 'adverb' 'adjective' '<pad>' '<pad>' '<pad>' '<pad>'\n",
      "  '<pad>' '<pad>']\n",
      " ['noun' 'verb' 'determiner' 'noun' 'preposition' 'adjective' 'noun'\n",
      "  '<pad>' '<pad>' '<pad>']\n",
      " ['noun' 'verb' 'adverb' 'adjective' 'verb' '<pad>' '<pad>' '<pad>'\n",
      "  '<pad>' '<pad>']]\n"
     ]
    }
   ],
   "source": [
    "y_string = np.array([item + ['<pad>'] * (max_length - len(item)) for item in pos])\n",
    "print(y_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 7 1 0 0 0 0 0 0 0]\n",
      " [4 7 2 1 0 0 0 0 0 0]\n",
      " [4 7 3 4 5 1 4 0 0 0]\n",
      " [4 7 2 1 7 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "y = np.array([list(map(lambda el : pos2idx.get(el), item)) for item in y_string])\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define SimPosRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PosRNN:\n",
    "  def __init__(self, seq_indices, seq_length, labels, num_classes, hidden_dim, max_length, word2idx):\n",
    "    # Data pipeline\n",
    "    with tf.variable_scope('input_layer'):\n",
    "      self._seq_indices = seq_indices\n",
    "      self._seq_length = seq_length\n",
    "      self._labels = labels\n",
    "\n",
    "      one_hot = tf.eye(len(word2idx), dtype = tf.float32)\n",
    "      self._one_hot = tf.get_variable(name='one_hot_embedding',\n",
    "                                      initializer=one_hot,\n",
    "                                      trainable=False) # embedding vector training 안할 것이기 때문\n",
    "      self._seq_embeddings = tf.nn.embedding_lookup(params=self._one_hot,\n",
    "                                                    ids=self._seq_indices)\n",
    "\n",
    "    # LSTM cell (many to many)\n",
    "    with tf.variable_scope('lstm_cell'):\n",
    "      cell = rnn.BasicLSTMCell(num_units=hidden_dim, state_is_tuple=True)\n",
    "      score_cell = rnn.OutputProjectionWrapper(cell=cell,\n",
    "                                               output_size=num_classes)\n",
    "      self._outputs, _ = tf.nn.dynamic_rnn(cell=score_cell, inputs=self._seq_embeddings,\n",
    "                                           sequence_length=self._seq_length,\n",
    "                                           dtype=tf.float32)\n",
    "\n",
    "    with tf.variable_scope('seq2seq_loss'):\n",
    "      masks = tf.sequence_mask(lengths=self._seq_length, maxlen=max_length, dtype=tf.float32)\n",
    "      self.seq2seq_loss = tf.contrib.seq2seq.sequence_loss(logits=self._outputs,\n",
    "                                                           targets=self._labels,\n",
    "                                                           weights=masks)\n",
    "\n",
    "    with tf.variable_scope('prediction'):\n",
    "      self._prediction = tf.argmax(input=self._outputs,\n",
    "                                   axis=2, output_type=tf.int32)\n",
    "\n",
    "  def predict(self, sess, seq_indices, seq_length):\n",
    "    feed_dict = {self._seq_indices : seq_indices, self._seq_length : seq_length}\n",
    "    return sess.run(self._prediction, feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a model of SimPosRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "num_classes = len(idx2pos)\n",
    "learning_rate = .003\n",
    "batch_size = 2\n",
    "max_epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up dataset with `tf.data`\n",
    "\n",
    "#### create input pipeline with `tf.data.Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((?, 10), (?,), (?, 10)), types: (tf.int64, tf.int64, tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "## create data pipeline with tf.data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_indices, X_length, y))\n",
    "train_dataset = train_dataset.shuffle(buffer_size = 100)\n",
    "train_dataset = train_dataset.batch(batch_size = batch_size)\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = train_dataset.make_initializable_iterator()\n",
    "seq_indices, seq_length, labels = train_iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_rnn = PosRNN(seq_indices=seq_indices, seq_length=seq_length,\n",
    "                 labels=labels, num_classes=num_classes,\n",
    "                 hidden_dim=16, max_length=max_length,\n",
    "                 word2idx=word2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creat training op and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create training op\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "train_op = optimizer.minimize(pos_rnn.seq2seq_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `tf.Session()` and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 1, step: 2, loss: 2.07756, (6.57 examples/sec; 0.304 sec/batch)\n",
      "epochs: 2, step: 4, loss: 2.06506, (252.65 examples/sec; 0.008 sec/batch)\n",
      "epochs: 3, step: 6, loss: 2.04792, (235.43 examples/sec; 0.008 sec/batch)\n",
      "epochs: 4, step: 8, loss: 2.0337, (243.67 examples/sec; 0.008 sec/batch)\n",
      "epochs: 5, step: 10, loss: 2.01939, (244.70 examples/sec; 0.008 sec/batch)\n",
      "epochs: 6, step: 12, loss: 2.00484, (242.00 examples/sec; 0.008 sec/batch)\n",
      "epochs: 7, step: 14, loss: 1.99397, (255.17 examples/sec; 0.008 sec/batch)\n",
      "epochs: 8, step: 16, loss: 1.97889, (248.82 examples/sec; 0.008 sec/batch)\n",
      "epochs: 9, step: 18, loss: 1.96329, (241.58 examples/sec; 0.008 sec/batch)\n",
      "epochs: 10, step: 20, loss: 1.94182, (246.46 examples/sec; 0.008 sec/batch)\n",
      "epochs: 11, step: 22, loss: 1.9256, (239.98 examples/sec; 0.008 sec/batch)\n",
      "epochs: 12, step: 24, loss: 1.90761, (252.24 examples/sec; 0.008 sec/batch)\n",
      "epochs: 13, step: 26, loss: 1.88803, (225.93 examples/sec; 0.009 sec/batch)\n",
      "epochs: 14, step: 28, loss: 1.86608, (240.53 examples/sec; 0.008 sec/batch)\n",
      "epochs: 15, step: 30, loss: 1.85397, (267.23 examples/sec; 0.007 sec/batch)\n",
      "epochs: 16, step: 32, loss: 1.82526, (236.92 examples/sec; 0.008 sec/batch)\n",
      "epochs: 17, step: 34, loss: 1.8028, (253.26 examples/sec; 0.008 sec/batch)\n",
      "epochs: 18, step: 36, loss: 1.77739, (251.19 examples/sec; 0.008 sec/batch)\n",
      "epochs: 19, step: 38, loss: 1.75184, (233.37 examples/sec; 0.009 sec/batch)\n",
      "epochs: 20, step: 40, loss: 1.73559, (248.88 examples/sec; 0.008 sec/batch)\n",
      "epochs: 21, step: 42, loss: 1.69631, (199.08 examples/sec; 0.010 sec/batch)\n",
      "epochs: 22, step: 44, loss: 1.67142, (196.68 examples/sec; 0.010 sec/batch)\n",
      "epochs: 23, step: 46, loss: 1.64432, (195.17 examples/sec; 0.010 sec/batch)\n",
      "epochs: 24, step: 48, loss: 1.61758, (220.85 examples/sec; 0.009 sec/batch)\n",
      "epochs: 25, step: 50, loss: 1.59274, (164.46 examples/sec; 0.012 sec/batch)\n",
      "epochs: 26, step: 52, loss: 1.5786, (195.31 examples/sec; 0.010 sec/batch)\n",
      "epochs: 27, step: 54, loss: 1.54285, (181.49 examples/sec; 0.011 sec/batch)\n",
      "epochs: 28, step: 56, loss: 1.52908, (150.48 examples/sec; 0.013 sec/batch)\n",
      "epochs: 29, step: 58, loss: 1.5052, (203.64 examples/sec; 0.010 sec/batch)\n",
      "epochs: 30, step: 60, loss: 1.47188, (185.84 examples/sec; 0.011 sec/batch)\n",
      "epochs: 31, step: 62, loss: 1.44929, (244.35 examples/sec; 0.008 sec/batch)\n",
      "epochs: 32, step: 64, loss: 1.43752, (255.21 examples/sec; 0.008 sec/batch)\n",
      "epochs: 33, step: 66, loss: 1.40695, (243.16 examples/sec; 0.008 sec/batch)\n",
      "epochs: 34, step: 68, loss: 1.39386, (287.65 examples/sec; 0.007 sec/batch)\n",
      "epochs: 35, step: 70, loss: 1.36359, (275.61 examples/sec; 0.007 sec/batch)\n",
      "epochs: 36, step: 72, loss: 1.34277, (262.56 examples/sec; 0.008 sec/batch)\n",
      "epochs: 37, step: 74, loss: 1.31962, (257.87 examples/sec; 0.008 sec/batch)\n",
      "epochs: 38, step: 76, loss: 1.30478, (236.33 examples/sec; 0.008 sec/batch)\n",
      "epochs: 39, step: 78, loss: 1.28159, (241.78 examples/sec; 0.008 sec/batch)\n",
      "epochs: 40, step: 80, loss: 1.24904, (238.69 examples/sec; 0.008 sec/batch)\n",
      "epochs: 41, step: 82, loss: 1.23478, (258.10 examples/sec; 0.008 sec/batch)\n",
      "epochs: 42, step: 84, loss: 1.21112, (230.84 examples/sec; 0.009 sec/batch)\n",
      "epochs: 43, step: 86, loss: 1.17909, (215.90 examples/sec; 0.009 sec/batch)\n",
      "epochs: 44, step: 88, loss: 1.15174, (216.10 examples/sec; 0.009 sec/batch)\n",
      "epochs: 45, step: 90, loss: 1.12589, (214.94 examples/sec; 0.009 sec/batch)\n",
      "epochs: 46, step: 92, loss: 1.10226, (210.22 examples/sec; 0.010 sec/batch)\n",
      "epochs: 47, step: 94, loss: 1.07369, (216.01 examples/sec; 0.009 sec/batch)\n",
      "epochs: 48, step: 96, loss: 1.04953, (145.51 examples/sec; 0.014 sec/batch)\n",
      "epochs: 49, step: 98, loss: 1.01823, (201.58 examples/sec; 0.010 sec/batch)\n",
      "epochs: 50, step: 100, loss: 0.993389, (240.62 examples/sec; 0.008 sec/batch)\n",
      "epochs: 51, step: 102, loss: 0.972524, (245.13 examples/sec; 0.008 sec/batch)\n",
      "epochs: 52, step: 104, loss: 0.938895, (247.25 examples/sec; 0.008 sec/batch)\n",
      "epochs: 53, step: 106, loss: 0.909691, (242.08 examples/sec; 0.008 sec/batch)\n",
      "epochs: 54, step: 108, loss: 0.889422, (257.37 examples/sec; 0.008 sec/batch)\n",
      "epochs: 55, step: 110, loss: 0.861428, (223.11 examples/sec; 0.009 sec/batch)\n",
      "epochs: 56, step: 112, loss: 0.833647, (246.60 examples/sec; 0.008 sec/batch)\n",
      "epochs: 57, step: 114, loss: 0.800376, (235.91 examples/sec; 0.008 sec/batch)\n",
      "epochs: 58, step: 116, loss: 0.766198, (241.98 examples/sec; 0.008 sec/batch)\n",
      "epochs: 59, step: 118, loss: 0.739837, (231.24 examples/sec; 0.009 sec/batch)\n",
      "epochs: 60, step: 120, loss: 0.721344, (252.02 examples/sec; 0.008 sec/batch)\n",
      "epochs: 61, step: 122, loss: 0.696542, (243.04 examples/sec; 0.008 sec/batch)\n",
      "epochs: 62, step: 124, loss: 0.680085, (247.84 examples/sec; 0.008 sec/batch)\n",
      "epochs: 63, step: 126, loss: 0.650013, (252.72 examples/sec; 0.008 sec/batch)\n",
      "epochs: 64, step: 128, loss: 0.61765, (211.48 examples/sec; 0.009 sec/batch)\n",
      "epochs: 65, step: 130, loss: 0.612063, (253.32 examples/sec; 0.008 sec/batch)\n",
      "epochs: 66, step: 132, loss: 0.574626, (228.50 examples/sec; 0.009 sec/batch)\n",
      "epochs: 67, step: 134, loss: 0.571989, (233.72 examples/sec; 0.009 sec/batch)\n",
      "epochs: 68, step: 136, loss: 0.551805, (219.41 examples/sec; 0.009 sec/batch)\n",
      "epochs: 69, step: 138, loss: 0.517099, (223.96 examples/sec; 0.009 sec/batch)\n",
      "epochs: 70, step: 140, loss: 0.514753, (251.92 examples/sec; 0.008 sec/batch)\n",
      "epochs: 71, step: 142, loss: 0.490754, (220.43 examples/sec; 0.009 sec/batch)\n",
      "epochs: 72, step: 144, loss: 0.480512, (235.13 examples/sec; 0.009 sec/batch)\n",
      "epochs: 73, step: 146, loss: 0.446438, (237.44 examples/sec; 0.008 sec/batch)\n",
      "epochs: 74, step: 148, loss: 0.449332, (183.34 examples/sec; 0.011 sec/batch)\n",
      "epochs: 75, step: 150, loss: 0.415151, (237.17 examples/sec; 0.008 sec/batch)\n",
      "epochs: 76, step: 152, loss: 0.411758, (253.19 examples/sec; 0.008 sec/batch)\n",
      "epochs: 77, step: 154, loss: 0.397389, (233.45 examples/sec; 0.009 sec/batch)\n",
      "epochs: 78, step: 156, loss: 0.391738, (251.48 examples/sec; 0.008 sec/batch)\n",
      "epochs: 79, step: 158, loss: 0.35891, (240.87 examples/sec; 0.008 sec/batch)\n",
      "epochs: 80, step: 160, loss: 0.357557, (247.66 examples/sec; 0.008 sec/batch)\n",
      "epochs: 81, step: 162, loss: 0.335137, (253.03 examples/sec; 0.008 sec/batch)\n",
      "epochs: 82, step: 164, loss: 0.332798, (242.33 examples/sec; 0.008 sec/batch)\n",
      "epochs: 83, step: 166, loss: 0.311794, (259.12 examples/sec; 0.008 sec/batch)\n",
      "epochs: 84, step: 168, loss: 0.299484, (248.76 examples/sec; 0.008 sec/batch)\n",
      "epochs: 85, step: 170, loss: 0.308525, (263.19 examples/sec; 0.008 sec/batch)\n",
      "epochs: 86, step: 172, loss: 0.280138, (254.90 examples/sec; 0.008 sec/batch)\n",
      "epochs: 87, step: 174, loss: 0.269124, (234.06 examples/sec; 0.009 sec/batch)\n",
      "epochs: 88, step: 176, loss: 0.259899, (246.58 examples/sec; 0.008 sec/batch)\n",
      "epochs: 89, step: 178, loss: 0.262193, (236.99 examples/sec; 0.008 sec/batch)\n",
      "epochs: 90, step: 180, loss: 0.261815, (274.05 examples/sec; 0.007 sec/batch)\n",
      "epochs: 91, step: 182, loss: 0.253422, (264.73 examples/sec; 0.008 sec/batch)\n",
      "epochs: 92, step: 184, loss: 0.245309, (251.79 examples/sec; 0.008 sec/batch)\n",
      "epochs: 93, step: 186, loss: 0.219916, (254.32 examples/sec; 0.008 sec/batch)\n",
      "epochs: 94, step: 188, loss: 0.211566, (249.81 examples/sec; 0.008 sec/batch)\n",
      "epochs: 95, step: 190, loss: 0.222709, (248.38 examples/sec; 0.008 sec/batch)\n",
      "epochs: 96, step: 192, loss: 0.216086, (244.89 examples/sec; 0.008 sec/batch)\n",
      "epochs: 97, step: 194, loss: 0.209352, (254.26 examples/sec; 0.008 sec/batch)\n",
      "epochs: 98, step: 196, loss: 0.195228, (208.33 examples/sec; 0.010 sec/batch)\n",
      "epochs: 99, step: 198, loss: 0.179752, (215.71 examples/sec; 0.009 sec/batch)\n",
      "epochs: 100, step: 200, loss: 0.183479, (235.50 examples/sec; 0.008 sec/batch)\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "loss_history = []\n",
    "step = 0\n",
    "for epochs in range(max_epochs):\n",
    "  start_time = time.time()\n",
    "  sess.run(train_iterator.initializer)\n",
    "  \n",
    "  avg_loss = []\n",
    "  while True:\n",
    "    try:\n",
    "      _, loss_ = sess.run([train_op, pos_rnn.seq2seq_loss])\n",
    "      avg_loss.append(loss_)\n",
    "      step += 1\n",
    "\n",
    "    except tf.errors.OutOfRangeError:\n",
    "      #print(\"End of dataset\")  # ==> \"End of dataset\"\n",
    "      break\n",
    "\n",
    "  avg_loss_ = np.mean(avg_loss)\n",
    "  loss_history.append(avg_loss_)\n",
    "  \n",
    "  duration = time.time() - start_time\n",
    "  examples_per_sec = batch_size / float(duration)\n",
    "  print(\"epochs: {}, step: {}, loss: {:g}, ({:.2f} examples/sec; {:.3f} sec/batch)\".format(epochs+1, step, avg_loss_, examples_per_sec, duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x119098a90>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history, label='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 7 1 0 0 0 0 0 0 0]\n",
      " [4 7 2 1 0 0 0 0 0 0]\n",
      " [4 7 3 4 5 1 4 0 0 0]\n",
      " [4 7 2 1 7 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = pos_rnn.predict(sess=sess, seq_indices=X_indices, seq_length=X_length)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Label:  pronoun verb adjective <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Prediction:  pronoun verb adjective <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "        Label:  noun verb adverb adjective <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Prediction:  noun verb adverb adjective <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "        Label:  noun verb determiner noun preposition adjective noun <pad> <pad> <pad>\n",
      "Prediction:  noun verb determiner noun preposition adjective noun <pad> <pad> <pad>\n",
      "        Label:  noun verb adverb adjective verb <pad> <pad> <pad> <pad> <pad>\n",
      "Prediction:  noun verb adverb adjective verb <pad> <pad> <pad> <pad> <pad>\n"
     ]
    }
   ],
   "source": [
    "result_str = []\n",
    "for example in y_pred:\n",
    "  result_str.append([idx2pos[idx] for idx in example])\n",
    "  \n",
    "for examples in zip(y_string, result_str):\n",
    "  print(\"        Label: \", ' '.join(examples[0]))\n",
    "  print(\"Prediction: \", ' '.join(examples[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
