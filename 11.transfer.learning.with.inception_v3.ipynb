{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer leaning using Inception-v3 network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#sys.path.append(\"$HOME/models/research/slim/\")\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "sess_config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/flowers/'\n",
    "tfrecord_filenames = [name for name in os.listdir(data_path) if 'tfrecord' in name]\n",
    "train_data_filenames = [os.path.join(data_path, name) for name in tfrecord_filenames if 'train' in name]\n",
    "validation_data_filenames = [os.path.join(data_path, name) for name in tfrecord_filenames if 'validation' in name]\n",
    "print(train_data_filenames)\n",
    "print(validation_data_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrecord_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms a scalar string `example_proto` into a pair of a scalar string and\n",
    "# a scalar integer, representing an image and its label, respectively.\n",
    "def _parse_function(example_proto):\n",
    "  features = {'image/encoded': tf.FixedLenFeature((), tf.string, default_value=\"\"),\n",
    "              'image/format': tf.FixedLenFeature((), tf.string, default_value=\"\"),\n",
    "              'image/class/label': tf.FixedLenFeature((), tf.int64, default_value=0),\n",
    "              'image/height': tf.FixedLenFeature((), tf.int64, default_value=0),\n",
    "              'image/width': tf.FixedLenFeature((), tf.int64, default_value=0)}\n",
    "  parsed_features = tf.parse_single_example(example_proto, features)\n",
    "  image = tf.image.decode_jpeg(parsed_features[\"image/encoded\"], channels=3)\n",
    "  image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "  label = tf.cast(parsed_features[\"image/class/label\"], dtype=tf.int32)\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocessing(image, label):\n",
    "  \"\"\"data augmentation function for training\n",
    "  augmentation method is borrowed by inception code\n",
    "  \n",
    "  Args:\n",
    "    image (3-rank Tensor): [?, ?, 3] for flower data\n",
    "    label (0-rank Tensor): scalar value of corresponding image\n",
    "    \n",
    "  Returns:\n",
    "    image (3-rank Tensor): [299, 299, 3] image transformed\n",
    "    label (0-rank Tensor): scalar value of corresponding image\n",
    "  \"\"\"\n",
    "  image = tf.image.resize_image_with_crop_or_pad(image, 299, 299)\n",
    "  image = tf.image.random_flip_left_right(image)\n",
    "  image = tf.image.random_brightness(image, max_delta=32./255.)\n",
    "  image = tf.image.random_saturation(image, lower=0.5, upper=1.5)\n",
    "  image = tf.image.random_hue(image, max_delta=0.2)\n",
    "  image = tf.image.random_contrast(image, lower=0.5, upper=1.5)\n",
    "  image = tf.clip_by_value(image, 0.0, 1.0)\n",
    "  # Finally, rescale to [-1, 1] instead of [0, 1)\n",
    "  image = tf.subtract(image, 0.5)\n",
    "  image = tf.multiply(image, 2.0)\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _central_crop(image, label):\n",
    "  \"\"\"data augmentation function for training\n",
    "  augmentation method is borrowed by inception code\n",
    "  \n",
    "  Args:\n",
    "    image (3-rank Tensor): [?, ?, 3] for flower data\n",
    "    label (0-rank Tensor): scalar value of corresponding image\n",
    "    \n",
    "  Returns:\n",
    "    image (3-rank Tensor): [299, 299, 3] image transformed\n",
    "    label (0-rank Tensor): scalar value of corresponding image\n",
    "  \"\"\"\n",
    "  image = tf.image.central_crop(image, central_fraction=0.875)\n",
    "  image = tf.image.resize_images(image, [299, 299])\n",
    "  # Finally, rescale to [-1, 1] instead of [0, 1)\n",
    "  image = tf.subtract(image, 0.5)\n",
    "  image = tf.multiply(image, 2.0)\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# for train\n",
    "train_dataset = tf.data.TFRecordDataset(train_data_filenames)\n",
    "train_dataset = train_dataset.map(_parse_function)\n",
    "train_dataset = train_dataset.map(_preprocessing)\n",
    "train_dataset = train_dataset.shuffle(buffer_size = 10000)\n",
    "train_dataset = train_dataset.batch(batch_size = batch_size)\n",
    "print(train_dataset)\n",
    "\n",
    "# for validation\n",
    "validation_dataset = tf.data.TFRecordDataset(validation_data_filenames)\n",
    "validation_dataset = validation_dataset.map(_parse_function)\n",
    "validation_dataset = validation_dataset.map(_central_crop)\n",
    "#validation_dataset = validation_dataset.shuffle(buffer_size = 10000)\n",
    "#validation_dataset = validation_dataset.batch(batch_size = batch_size)\n",
    "validation_dataset = validation_dataset.batch(batch_size = 350)\n",
    "print(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.data.Iterator.from_string_handle의 output_shapes는 default = None이지만 꼭 값을 넣는 게 좋음\n",
    "handle = tf.placeholder(tf.string, shape=[])\n",
    "iterator = tf.data.Iterator.from_string_handle(handle,\n",
    "                                               train_dataset.output_types,\n",
    "                                               train_dataset.output_shapes)\n",
    "inputs, labels = iterator.get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a Inception-v3 graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nets import inception_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_training = tf.placeholder(tf.bool)\n",
    "with slim.arg_scope(inception_v3.inception_v3_arg_scope(weight_decay=0.00004)):\n",
    "  logits, _ = inception_v3.inception_v3(inputs, num_classes=5, is_training=is_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_variables_to_train(trainable_scopes):\n",
    "  \"\"\"Returns a list of variables to train.\n",
    "\n",
    "  Returns:\n",
    "    A list of variables to train by the optimizer.\n",
    "  \"\"\"\n",
    "  if trainable_scopes is None:\n",
    "    return tf.trainable_variables()\n",
    "  else:\n",
    "    scopes = [scope.strip() for scope in trainable_scopes.split(',')]\n",
    "\n",
    "  variables_to_train = []\n",
    "  for scope in scopes:\n",
    "    variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope)\n",
    "    variables_to_train.extend(variables)\n",
    "  return variables_to_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_scopes = 'InceptionV3/Logits,InceptionV3/AuxLogits'\n",
    "variables_to_train = _get_variables_to_train(trainable_scopes)\n",
    "\n",
    "for var in variables_to_train:\n",
    "  print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_one_hot = tf.one_hot(y, depth=10)\n",
    "#cross_entropy = tf.losses.softmax_cross_entropy(onehot_labels=y_one_hot, logits=y_pred)\n",
    "cross_entropy = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "l2_regualrization_loss = tf.reduce_sum(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))\n",
    "\n",
    "with tf.name_scope('total_loss'):\n",
    "  total_loss = cross_entropy + l2_regualrization_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch normalization update\n",
    "batchnorm_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "# Add dependency to compute batchnorm_updates.\n",
    "with tf.control_dependencies(batchnorm_update_ops):\n",
    "  train_step = tf.train.RMSPropOptimizer(0.01).minimize(total_loss,\n",
    "                                                        var_list=tf.trainable_variables()[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_location = 'graphs/11.transfer.learning.with.inception_v3'\n",
    "print('Saving graph to: %s' % graph_location)\n",
    "train_writer = tf.summary.FileWriter(graph_location)\n",
    "train_writer.add_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('summaries'):\n",
    "  tf.summary.scalar('loss/cross_entropy', cross_entropy)\n",
    "  tf.summary.scalar('loss/l2_regualrization_loss', l2_regualrization_loss)\n",
    "  tf.summary.scalar('loss/total_loss', total_loss)\n",
    "  tf.summary.image('images', inputs)\n",
    "  for var in tf.trainable_variables():\n",
    "    tf.summary.histogram(var.op.name, var)\n",
    "  # merge all summaries\n",
    "  summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_init_fn(checkpoint_exclude_scopes):\n",
    "  \"\"\"Returns a function run by the chief worker to warm-start the training.\n",
    "\n",
    "  Note that the init_fn is only run when initializing the model during the very\n",
    "  first global step.\n",
    "\n",
    "  Returns:\n",
    "    An init function run by the supervisor.\n",
    "  \"\"\"\n",
    "  exclusions = []\n",
    "  if checkpoint_exclude_scopes:\n",
    "    exclusions = [scope.strip()\n",
    "                  for scope in checkpoint_exclude_scopes.split(',')]\n",
    "\n",
    "  # TODO(sguada) variables.filter_variables()\n",
    "  variables_to_restore = []\n",
    "  for var in slim.get_model_variables():\n",
    "    for exclusion in exclusions:\n",
    "      if var.op.name.startswith(exclusion):\n",
    "        break\n",
    "    else:\n",
    "      variables_to_restore.append(var)\n",
    "\n",
    "  return variables_to_restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_exclude_scopes = 'InceptionV3/Logits,InceptionV3/AuxLogits'\n",
    "variables_to_restore = _get_init_fn(checkpoint_exclude_scopes)\n",
    "for var in variables_to_restore:\n",
    "  print(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the Inception-v3 checkpoint: \n",
    "\n",
    "```\n",
    "$ CHECKPOINT_DIR='../checkpoints'\n",
    "$ mkdir ${CHECKPOINT_DIR}\n",
    "$ wget http://download.tensorflow.org/models/inception_v3_2016_08_28.tar.gz\n",
    "$ tar -xvf inception_v3_2016_08_28.tar.gz\n",
    "$ mv inception_v3_2016_08_28.tar.gz ${CHECKPOINT_DIR}\n",
    "$ rm inception_v3_2016_08_28.tar.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the Inception-v3 checkpoint: \n",
    "# if you already have a inception_v3.ckpt then skip and comment below commands\n",
    "#!mkdir ../checkpoints\n",
    "#!wget http://download.tensorflow.org/models/inception_v3_2016_08_28.tar.gz\n",
    "#!tar -xvf inception_v3_2016_08_28.tar.gz\n",
    "#!mv inception_v3.ckpt ../checkpoints\n",
    "#!rm inception_v3_2016_08_28.tar.gz\n",
    "#print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore Inception_v3 weights using `tf.saver.restore`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver(variables_to_restore)\n",
    "\n",
    "sess = tf.Session(config=sess_config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# use saver object to load variables from the saved model\n",
    "saver.restore(sess, \"../checkpoints/inception_v3.ckpt\")\n",
    "\n",
    "# train_iterator\n",
    "train_iterator = train_dataset.make_initializable_iterator()\n",
    "train_handle = sess.run(train_iterator.string_handle())\n",
    "\n",
    "# Train\n",
    "max_epochs = 10\n",
    "step = 0\n",
    "for epochs in range(max_epochs):\n",
    "  sess.run(train_iterator.initializer)\n",
    "\n",
    "  while True:\n",
    "    try:\n",
    "      start_time = time.time()\n",
    "      _, loss = sess.run([train_step, total_loss],\n",
    "                         feed_dict={handle: train_handle,\n",
    "                                    is_training: True})\n",
    "      if step % 10 == 0:\n",
    "        duration = time.time() - start_time\n",
    "        examples_per_sec = batch_size / float(duration)\n",
    "        print(\"epochs: {}, step: {}, loss: {:g}, ({:.2f} examples/sec; {:.3f} sec/batch)\".format(epochs, step, loss, examples_per_sec, duration))\n",
    "        \n",
    "      if step % 2000 == 0:\n",
    "        # summary\n",
    "        summary_str = sess.run(summary_op, feed_dict={handle: train_handle, is_training: False})\n",
    "        train_writer.add_summary(summary_str, global_step=step)\n",
    "        \n",
    "      step += 1\n",
    "      #if step > 100:\n",
    "      #  break\n",
    "\n",
    "    except tf.errors.OutOfRangeError:\n",
    "      print(\"End of dataset\")  # ==> \"End of dataset\"\n",
    "      break\n",
    "\n",
    "train_writer.close()\n",
    "print(\"training done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation_iterator\n",
    "validation_iterator = validation_dataset.make_initializable_iterator()\n",
    "validation_handle = sess.run(validation_iterator.string_handle())\n",
    "sess.run(validation_iterator.initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, acc_op = tf.metrics.accuracy(labels=labels, predictions=tf.argmax(logits, 1), name='accuracy')\n",
    "sess.run(tf.local_variables_initializer())\n",
    "\n",
    "sess.run(acc_op, feed_dict={handle: validation_handle, is_training: False})\n",
    "print(\"test accuracy:\", sess.run(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
