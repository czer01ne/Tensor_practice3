{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG19 network using slim\n",
    "\n",
    "* Prerequisites\n",
    "  * `git clone https://github.com/tensorflow/models.git`\n",
    "  * [Pretrained models](https://github.com/tensorflow/models/tree/master/research/slim#pre-trained-models)\n",
    "  \n",
    "* Add path to system enviornment\n",
    "```bash\n",
    "export PYTHONPATH=\"$HOME/models/research/slim/:$PYTHONPATH\"\n",
    "```\n",
    "* or use `sys.path.append` like below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# put your tensorflow \"models\" absolute path\n",
    "sys.path.append(\"/Users/ilguyi/models/research/slim\")\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "sess_config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a VGG19 graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nets import vgg\n",
    "# When you don't have a tensorflow models folder, use below syntax\n",
    "#from tensorflow.contrib.slim.nets import vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.placeholder(tf.float32, [None, 224, 224, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with slim.arg_scope(vgg.vgg_arg_scope()):\n",
    "  logits, end_points = vgg.vgg_19(inputs, num_classes=1000, is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in end_points:\n",
    "  print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "  writer = tf.summary.FileWriter(\"./graphs/08.vgg19.slim\", sess.graph)\n",
    "  writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the VGG19 checkpoint: \n",
    "\n",
    "```\n",
    "$ CHECKPOINT_DIR='../checkpoints'\n",
    "$ mkdir ${CHECKPOINT_DIR}\n",
    "$ wget http://download.tensorflow.org/models/vgg_19_2016_08_28.tar.gz\n",
    "$ tar -xvf vgg_19_2016_08_28.tar.gz\n",
    "$ mv vgg_19.ckpt ${CHECKPOINT_DIR}\n",
    "$ rm vgg_19_2016_08_28.tar.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the VGG19 checkpoint: \n",
    "# if you already have a vgg_19.ckpt then skip and comment below commands\n",
    "#!mkdir ../checkpoints\n",
    "#!wget http://download.tensorflow.org/models/vgg_19_2016_08_28.tar.gz\n",
    "#!tar -xvf vgg_19_2016_08_28.tar.gz\n",
    "#!mv vgg_19.ckpt ../checkpoints\n",
    "#!rm vgg_19_2016_08_28.tar.gz\n",
    "#print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore VGG19 weights using `tf.saver.restore`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read a image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_preprocessing(image):\n",
    "  \"\"\"image preprocessing\n",
    "\n",
    "  Args:\n",
    "    image (PIL image): image with shape [height, width, channels]\n",
    "    \n",
    "  Returns:\n",
    "    image (np.float32): vgg preprocessed image with 4-rank tensor shape [1, height, width, channels] applied by mean_image_subtraction\n",
    "  \"\"\"\n",
    "  norm_means = np.array([123.68, 116.779, 103.939])\n",
    "  vgg_image_size = 224\n",
    "  image = image.resize((vgg_image_size, vgg_image_size))\n",
    "  image = np.asarray(image)\n",
    "  image = image.astype(np.float32)\n",
    "  image -= norm_means\n",
    "  \n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_image = Image.open('../input_data/cat2.jpg')\n",
    "my_image = vgg_preprocessing(my_image)\n",
    "my_image = np.expand_dims(image, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(config=sess_config) as sess:\n",
    "\n",
    "  # use saver object to load variables from the saved model\n",
    "  saver.restore(sess, \"../checkpoints/vgg_19.ckpt\")\n",
    "  \n",
    "  # print conv1_1 weight itself\n",
    "  conv1_1_w = sess.run(tf.trainable_variables()[0])\n",
    "  \n",
    "  # print feature maps\n",
    "  conv1_1, conv2_1, \\\n",
    "  conv3_2, conv4_3, \\\n",
    "  conv5_3 = sess.run([end_points['vgg_19/conv1/conv1_1'],\n",
    "                      end_points['vgg_19/conv2/conv2_1'],\n",
    "                      end_points['vgg_19/conv3/conv3_2'],\n",
    "                      end_points['vgg_19/conv4/conv4_3'],\n",
    "                      end_points['vgg_19/conv5/conv5_3']],\n",
    "                     feed_dict={inputs: my_image})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_all_feature_maps(layer, layer_name):\n",
    "  \"\"\"Print all feature maps\n",
    "    This code is borrowed from \"Deep Learning with Python\" (by F. Chollet)\n",
    "  \n",
    "  Args:\n",
    "    layer (4-rank Tensor): feature maps\n",
    "    layer_name (string): name of feature maps\n",
    "    \n",
    "  Returns:\n",
    "    print all feature maps\n",
    "  \"\"\"\n",
    "  num_features = layer.shape[-1]\n",
    "  size = layer.shape[1]\n",
    "  images_per_row = 16\n",
    "  for feature_map in range(num_features):\n",
    "    num_cols = num_features // images_per_row\n",
    "    display_grid = np.zeros((size * num_cols, images_per_row * size))\n",
    "\n",
    "    for col in range(num_cols):\n",
    "      for row in range(images_per_row):\n",
    "        channel_image = layer[0,:,:,col * images_per_row + row]\n",
    "\n",
    "        channel_image -= channel_image.mean()\n",
    "        channel_image /= channel_image.std()\n",
    "        channel_image *= 64\n",
    "        channel_image += 128\n",
    "        channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "\n",
    "        display_grid[col * size : (col + 1) * size,\n",
    "                     row * size : (row + 1) * size] = channel_image\n",
    "\n",
    "  scale = 1. / size\n",
    "  plt.figure(figsize=(scale * display_grid.shape[1],\n",
    "                      scale * display_grid.shape[0]))\n",
    "  plt.title(layer_name)\n",
    "  plt.grid(False)\n",
    "  plt.imshow(display_grid, aspect='auto', cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print feature maps of conv1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_all_feature_maps(conv1_1, 'conv1_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print feature maps of conv2_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_all_feature_maps(conv2_1, 'conv2_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print feature maps of conv3_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_all_feature_maps(conv3_2, 'conv3_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print feature maps of conv4_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_all_feature_maps(conv4_3, 'conv4_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print feature maps of conv5_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_all_feature_maps(conv5_3, 'conv5_3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
