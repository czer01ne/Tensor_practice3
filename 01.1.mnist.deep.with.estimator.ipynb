{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Guide to TF Layers: Building a Convolutional Neural Network\n",
    "\n",
    "* [MNIST tutorials](https://www.tensorflow.org/tutorials/layers)\n",
    "\n",
    "![MNIST](../../figures/mnist_0-9.png)\n",
    "* training dataset: 60000\n",
    "* test dataset: 10000\n",
    "* one example: gray scale image with $28 \\times 28$ size\n",
    "* [`cnn_mnist.py`](https://github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/examples/tutorials/layers/cnn_mnist.py) 참고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Convolutional Neural Network Estimator for MNIST, built with tf.layers.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional neural networks\n",
    "\n",
    "* Convolutional layers\n",
    "  * $\\textrm{ReLU}({\\bf x} * {\\bf w} + {\\bf b})$\n",
    "  * $*$: convolution operator\n",
    "* Pooling layers\n",
    "  * down sampling: `max-pooling`, `average-pooling`\n",
    "* Dense (fully connected) layers\n",
    "  * $\\textrm{ReLU}({\\bf w} {\\bf x} + {\\bf b})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure of LeNet 5\n",
    "\n",
    "![LeNet5](../figures/Lenet5.png)\n",
    "\n",
    "* Convolutional Layer #1: Applies 32 5x5 filters (extracting 5x5-pixel subregions), with ReLU activation function\n",
    "* Pooling Layer #1: Performs max pooling with a 2x2 filter and stride of 2 (which specifies that pooled regions do not overlap)\n",
    "* Convolutional Layer #2: Applies 64 5x5 filters, with ReLU activation function\n",
    "* Pooling Layer #2: Again, performs max pooling with a 2x2 filter and stride of 2\n",
    "* Dense Layer #1: 1,024 neurons, with dropout regularization rate of 0.4 (probability of 0.4 that any given element will be dropped during training)\n",
    "* Dense Layer #2 (Logits Layer): 10 neurons, one for each digit target class (0–9)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN model with `tf.layers` APIs\n",
    "\n",
    "* [`tf.layers`](https://www.tensorflow.org/api_docs/python/tf/layers) 링크\n",
    "* [`tf.layers.conv2d()`](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d)\n",
    "* `tf.layers.max_pooling2d()`\n",
    "* `tf.layers.dense()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(219)\n",
    "\n",
    "def cnn_model_fn(features, labels, mode):\n",
    "  \"\"\"Model function for CNN.\"\"\"\n",
    "  # Input Layer\n",
    "  # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n",
    "  # MNIST images are 28x28 pixels, and have one color channel\n",
    "  input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "\n",
    "  # Convolutional Layer #1\n",
    "  # Computes 32 features using a 5x5 filter with ReLU activation.\n",
    "  # Padding is added to preserve width and height.\n",
    "  # Input Tensor Shape: [batch_size, 28, 28, 1]\n",
    "  # Output Tensor Shape: [batch_size, 28, 28, 32]\n",
    "  conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  # Pooling Layer #1\n",
    "  # First max pooling layer with a 2x2 filter and stride of 2\n",
    "  # Input Tensor Shape: [batch_size, 28, 28, 32]\n",
    "  # Output Tensor Shape: [batch_size, 14, 14, 32]\n",
    "  pool1 = tf.layers.max_pooling2d(inputs=conv1,\n",
    "                                  pool_size=[2, 2],\n",
    "                                  strides=2)\n",
    "\n",
    "  # Convolutional Layer #2\n",
    "  # Computes 64 features using a 5x5 filter.\n",
    "  # Padding is added to preserve width and height.\n",
    "  # Input Tensor Shape: [batch_size, 14, 14, 32]\n",
    "  # Output Tensor Shape: [batch_size, 14, 14, 64]\n",
    "  conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=64,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  # Pooling Layer #2\n",
    "  # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "  # Input Tensor Shape: [batch_size, 14, 14, 64]\n",
    "  # Output Tensor Shape: [batch_size, 7, 7, 64]\n",
    "  pool2 = tf.layers.max_pooling2d(inputs=conv2,\n",
    "                                  pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Flatten tensor into a batch of vectors\n",
    "  # Input Tensor Shape: [batch_size, 7, 7, 64]\n",
    "  # Output Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "\n",
    "  # Dense Layer\n",
    "  # Densely connected layer with 1024 neurons\n",
    "  # Input Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "  # Output Tensor Shape: [batch_size, 1024]\n",
    "  dense = tf.layers.dense(inputs=pool2_flat,\n",
    "                          units=1024,\n",
    "                          activation=tf.nn.relu)\n",
    "\n",
    "  # Add dropout operation; 0.6 probability that element will be kept\n",
    "  dropout = tf.layers.dropout(\n",
    "      inputs=dense, rate=0.4,\n",
    "    training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "  # Logits layer\n",
    "  # Input Tensor Shape: [batch_size, 1024]\n",
    "  # Output Tensor Shape: [batch_size, 10]\n",
    "  logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "\n",
    "  predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "      # `logging_hook`.\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "  }\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "  # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "  loss = tf.losses.sparse_softmax_cross_entropy(\n",
    "    labels=labels,\n",
    "    logits=logits)\n",
    "\n",
    "  # Configure the Training Op (for TRAIN mode)\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "    train_op = optimizer.minimize(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "  # Add evaluation metrics (for EVAL mode)\n",
    "  eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])}\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input layer\n",
    "\n",
    "* 4-rank Tensor: `[batch_size, image_height, image_width, channels]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conv2d layer\n",
    "\n",
    "* [`tf.layers.conv2d()`](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d) API\n",
    "* 필수 arguments\n",
    "```\n",
    "tf.layers.conv2d(\n",
    "        inputs,\n",
    "        filters,\n",
    "        kernel_size)\n",
    "```\n",
    "* `inputs`: 4-rank Tensor: `[batch_size, image_height, image_width, channels]`\n",
    "* `filters`: output filter의 갯수\n",
    "* `kernel_size`: `[height, width]`\n",
    "* `padding`: `\"valid\"` or `\"same\"` (case-insensitive)\n",
    "  * `valid`: [32 x 32] -> [28 x 28] (`kernel_size`: 5)\n",
    "  * `same`: [32 x 32] -> [32 x 32] (`kernel_size`: 5)\n",
    "* `activation`\n",
    "  * 기본값이 None\n",
    "  * `tf.nn.relu`를 습관적으로 해주는게 좋음 (맨 마지막 레이어를 제외하고)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### maxpooling2d layer\n",
    "\n",
    "* [`tf.layers.maxpooling2d()`](https://www.tensorflow.org/api_docs/python/tf/layers/max_pooling2d) API\n",
    "* 필수 arguments\n",
    "```\n",
    "tf.layers.maxpooling2d(\n",
    "        inputs,\n",
    "        pool_size,\n",
    "        strides)\n",
    "```\n",
    "* `inputs`: 4-rank Tensor: `[batch_size, image_height, image_width, channels]`\n",
    "* `pool_size`: `[height, width]`\n",
    "* `strides`: `[height, width]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dense layer\n",
    "\n",
    "* [`tf.layers.dense()`](https://www.tensorflow.org/api_docs/python/tf/layers/dense) API\n",
    "* 필수 arguments\n",
    "```\n",
    "tf.layers.dense(\n",
    "        inputs,\n",
    "        units)\n",
    "```\n",
    "* `inputs`: 2-rank Tensor: `[batch_size, features]`\n",
    "* `units`: output node 갯수\n",
    "* `conv2d`나 `maxpooling2d` 뒤에 `dense`레이어를 쓰려면 `inputs` 텐서의 차원을 맞춰줘야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dropout layer\n",
    "\n",
    "* [`tf.layers.dropout()`](https://www.tensorflow.org/api_docs/python/tf/layers/dropout) API\n",
    "* 필수 arguments\n",
    "```\n",
    "tf.layers.dropout(\n",
    "        inputs\n",
    "        rate=0.5,\n",
    "        training=False)\n",
    "```\n",
    "* `inputs`: 2-rank Tensor: `[batch_size, features]`\n",
    "* `rate`: dropout rate\n",
    "* `training`: `training` mode인지 아닌지 구분해주는 `argument`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logits layer\n",
    "\n",
    "* `softmax`를 하기 전에 score 값(raw value)을 전달해 주는 `layer`\n",
    "* `activation`을 하지 않는게 중요\n",
    "* `units`갯수는 class 갯수와 동일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate predictions\n",
    "\n",
    "* `predicted class` for each example\n",
    "  * [`tf.argmax`](https://www.tensorflow.org/api_docs/python/tf/argmax) 사용\n",
    "* `probabilities` for each possible target class for each example\n",
    "  * [`tf.nn.softmax`](https://www.tensorflow.org/api_docs/python/tf/nn/softmax) 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate loss\n",
    "\n",
    "* multiclass classification problems\n",
    "  * `cross_entropy` loss: $- \\sum y \\log \\hat{y}$\n",
    "  * `tf.losses.softmax_cross_entropy` API 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the Training Op\n",
    "\n",
    "* stochastic gradient descent\n",
    "* [Optimizers API](https://www.tensorflow.org/api_guides/python/train#Optimizers)\n",
    "```\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "train_op = optimizer.minimize(\n",
    "      loss=loss,\n",
    "      global_step=tf.train.get_global_step())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add evaluation metrics\n",
    "\n",
    "```\n",
    "eval_metric_ops = {\n",
    "    \"accuracy\": tf.metrics.accuracy(\n",
    "        labels=labels, predictions=predictions[\"classes\"])}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and eval data from tf.keras\n",
    "(train_data, train_labels), (test_data, test_labels) = \\\n",
    "    tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_data = train_data / 255.\n",
    "train_data = train_data.reshape(-1, 784)\n",
    "train_labels = np.asarray(train_labels, dtype=np.int32)\n",
    "\n",
    "test_data = test_data / 255.\n",
    "test_data = test_data.reshape(-1, 784)\n",
    "test_labels = np.asarray(test_labels, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'graphs/01.1.mnist.deep.with.estimator', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x114f27828>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Create the Estimator\n",
    "mnist_classifier = tf.estimator.Estimator(\n",
    "    model_fn=cnn_model_fn, model_dir=\"graphs/01.1.mnist.deep.with.estimator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging for predictions\n",
    "# Log the values in the \"Softmax\" tensor with label \"probabilities\"\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "    tensors=tensors_to_log, every_n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into graphs/01.1.mnist.deep.with.estimator/model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[0.11085267 0.09661379 0.09054571 0.09537333 0.09872086 0.09748218\n",
      "  0.08516066 0.10031059 0.11402366 0.11091654]\n",
      " [0.10216477 0.09833109 0.09262585 0.10654036 0.07884404 0.09112105\n",
      "  0.09526109 0.11633983 0.10620461 0.11256731]\n",
      " [0.12023828 0.10430048 0.09363581 0.09349001 0.07899735 0.09837458\n",
      "  0.09368561 0.1136611  0.1015895  0.10202728]\n",
      " [0.11521779 0.09471434 0.10311346 0.10221873 0.07435234 0.08956385\n",
      "  0.0959575  0.11265201 0.11251908 0.09969089]\n",
      " [0.10446007 0.10477688 0.08756909 0.09905363 0.08620441 0.10184618\n",
      "  0.0946432  0.0983346  0.11065778 0.11245416]\n",
      " [0.11196024 0.09928653 0.09017645 0.10362386 0.09432775 0.08764893\n",
      "  0.09210041 0.10295333 0.11643351 0.10148899]\n",
      " [0.11682819 0.10329837 0.08517468 0.09041092 0.0885213  0.09020091\n",
      "  0.08515739 0.10774618 0.1256912  0.10697086]\n",
      " [0.10457483 0.09729156 0.08857681 0.10741583 0.0944612  0.10208112\n",
      "  0.0961679  0.09266427 0.11305027 0.10371622]\n",
      " [0.11598992 0.11372551 0.07937564 0.09071291 0.08202424 0.07351122\n",
      "  0.10535379 0.12637645 0.11662952 0.0963008 ]\n",
      " [0.10517443 0.10612336 0.0863411  0.10110157 0.09480199 0.09059158\n",
      "  0.08415846 0.10419213 0.12580893 0.10170645]\n",
      " [0.12016501 0.10532323 0.09427059 0.102976   0.08873708 0.09400286\n",
      "  0.08602553 0.09942936 0.10561737 0.10345297]\n",
      " [0.09800015 0.10443597 0.09178985 0.09291854 0.07405278 0.08685405\n",
      "  0.09604651 0.10993153 0.13992143 0.10604919]\n",
      " [0.1171998  0.10071213 0.09273123 0.0982443  0.09979319 0.10585279\n",
      "  0.0796691  0.09450748 0.10947184 0.10181814]\n",
      " [0.1100395  0.10393741 0.09666944 0.09557348 0.0971076  0.0960236\n",
      "  0.09824429 0.10020172 0.10916393 0.09303904]\n",
      " [0.10504019 0.0989147  0.09318911 0.10263802 0.08594743 0.10147788\n",
      "  0.09174914 0.11920722 0.10749142 0.09434489]\n",
      " [0.11032051 0.10545854 0.08735012 0.10333791 0.08663992 0.09385091\n",
      "  0.08871411 0.11129686 0.11659851 0.0964326 ]\n",
      " [0.10551587 0.08692829 0.0926939  0.10271159 0.08612844 0.09158725\n",
      "  0.10097924 0.09893283 0.12285323 0.11166937]\n",
      " [0.10194674 0.11029281 0.08734674 0.10092586 0.08562003 0.09721787\n",
      "  0.08888905 0.10438234 0.11125478 0.11212378]\n",
      " [0.11105251 0.10320425 0.08418019 0.11196989 0.0889287  0.09303117\n",
      "  0.10052089 0.09420423 0.12099393 0.09191424]\n",
      " [0.11084057 0.11621392 0.0842837  0.09953054 0.09202967 0.08252975\n",
      "  0.09824836 0.11480637 0.10051547 0.10100166]\n",
      " [0.10563157 0.09916102 0.10575778 0.11017852 0.08629864 0.08787313\n",
      "  0.0932198  0.11282882 0.10074761 0.09830313]\n",
      " [0.10862262 0.106692   0.10813847 0.09558428 0.093213   0.10020187\n",
      "  0.07773258 0.09874421 0.11082594 0.10024503]\n",
      " [0.10957933 0.10580828 0.09346354 0.09607938 0.08705337 0.10567229\n",
      "  0.0982929  0.10710777 0.09820276 0.09874037]\n",
      " [0.11922742 0.08724704 0.09244502 0.11531687 0.08608353 0.08301918\n",
      "  0.10295061 0.12282986 0.09716945 0.09371101]\n",
      " [0.10859675 0.10491278 0.0794508  0.09966575 0.08649529 0.10664036\n",
      "  0.09347775 0.09938291 0.11620479 0.10517282]\n",
      " [0.10131136 0.10610477 0.09034805 0.10231525 0.09394884 0.0961867\n",
      "  0.09467242 0.10685477 0.10388509 0.10437273]\n",
      " [0.10613423 0.11134494 0.0882693  0.09396044 0.09527713 0.10161096\n",
      "  0.08344049 0.10821768 0.10862895 0.10311588]\n",
      " [0.10312066 0.10042472 0.10516257 0.10027703 0.08160746 0.08701659\n",
      "  0.08622604 0.10930768 0.11516234 0.11169492]\n",
      " [0.10060388 0.10136265 0.08665145 0.11827573 0.08950779 0.08257976\n",
      "  0.08877997 0.11255695 0.12719919 0.09248265]\n",
      " [0.10919323 0.10142494 0.08694398 0.10126902 0.08861749 0.09583632\n",
      "  0.09148568 0.10271943 0.1049484  0.11756151]\n",
      " [0.12639088 0.09352959 0.10030584 0.09821057 0.08846399 0.10795185\n",
      "  0.08916077 0.10649312 0.09721079 0.09228262]\n",
      " [0.10053077 0.10486352 0.11461479 0.09873212 0.08310701 0.08487719\n",
      "  0.09471472 0.10483899 0.11690609 0.09681481]]\n",
      "INFO:tensorflow:loss = 2.30942440032959, step = 1\n",
      "INFO:tensorflow:probabilities = [[0.00033401 0.00000717 0.00001277 0.03863748 0.0000619  0.00057043\n",
      "  0.00000288 0.03939121 0.00753597 0.91344618]\n",
      " [0.00824137 0.00716973 0.03494416 0.01625823 0.00582697 0.00298346\n",
      "  0.00330641 0.66330944 0.01920269 0.23875754]\n",
      " [0.00034456 0.00042863 0.00155812 0.00070325 0.00294797 0.00035241\n",
      "  0.98928497 0.00000316 0.00214716 0.00222978]\n",
      " [0.00302711 0.05261167 0.00102061 0.00237937 0.03993057 0.01369997\n",
      "  0.63997654 0.00005803 0.16792032 0.07937582]\n",
      " [0.00048271 0.00001941 0.02211865 0.38382685 0.00015717 0.00045145\n",
      "  0.00007158 0.00027084 0.55591169 0.03668964]\n",
      " [0.0239119  0.00008585 0.00072362 0.02188474 0.00727552 0.82868956\n",
      "  0.00334035 0.00038677 0.02990271 0.08379898]\n",
      " [0.00314727 0.00002073 0.02273585 0.02005539 0.00008088 0.00173019\n",
      "  0.0001199  0.0000782  0.94824136 0.00379022]\n",
      " [0.0007779  0.00125736 0.00000619 0.03058775 0.00043969 0.91153741\n",
      "  0.00001866 0.00269568 0.03243831 0.02024104]\n",
      " [0.00059088 0.00342685 0.01950792 0.95991005 0.0000527  0.0057146\n",
      "  0.00009474 0.00012628 0.01043558 0.00014041]\n",
      " [0.00011688 0.00026265 0.0001176  0.96623872 0.00006137 0.00103079\n",
      "  0.00000661 0.00077798 0.01380203 0.01758535]\n",
      " [0.000048   0.99487878 0.00063024 0.00024248 0.00060211 0.0000555\n",
      "  0.00011784 0.00014485 0.00258497 0.00069523]\n",
      " [0.00001756 0.00000078 0.99992402 0.00000525 0.00000081 0.00000049\n",
      "  0.00002228 0.         0.00002854 0.00000027]\n",
      " [0.00014544 0.00000723 0.00003594 0.00001591 0.00005022 0.00004079\n",
      "  0.99954888 0.00000009 0.00008648 0.00006902]\n",
      " [0.0012106  0.00697022 0.00700429 0.02907242 0.0020138  0.00065394\n",
      "  0.00051873 0.00028906 0.92279985 0.02946708]\n",
      " [0.00160543 0.00003762 0.00093061 0.00002059 0.95098415 0.0002708\n",
      "  0.02006956 0.00002131 0.00036883 0.0256911 ]\n",
      " [0.00188577 0.88389989 0.01884005 0.00418516 0.01439013 0.00179758\n",
      "  0.0023973  0.0065432  0.05383137 0.01222955]\n",
      " [0.00003086 0.00043586 0.0000201  0.0001445  0.00276146 0.00016622\n",
      "  0.00007509 0.00384628 0.00554808 0.98697154]\n",
      " [0.00055183 0.93029597 0.01581138 0.00574305 0.0010491  0.00060839\n",
      "  0.0026288  0.00011668 0.03700761 0.00618719]\n",
      " [0.00036891 0.95198304 0.00075285 0.0064135  0.00529419 0.00236399\n",
      "  0.00233812 0.00977002 0.00309522 0.01762015]\n",
      " [0.99758572 0.00000199 0.00047066 0.00004932 0.000005   0.00075421\n",
      "  0.00083376 0.00000084 0.00012846 0.00017004]\n",
      " [0.00004866 0.99057974 0.00032838 0.00146026 0.00094956 0.00010651\n",
      "  0.00061185 0.00044194 0.0044507  0.0010224 ]\n",
      " [0.00003064 0.00047091 0.00000974 0.00057059 0.01293371 0.00018771\n",
      "  0.00005901 0.00491089 0.00573977 0.97508705]\n",
      " [0.99917015 0.00000012 0.00016124 0.00004161 0.00000024 0.00045716\n",
      "  0.0000269  0.00000054 0.00013663 0.0000054 ]\n",
      " [0.99724145 0.00000017 0.00000454 0.000085   0.00000452 0.00211508\n",
      "  0.00008933 0.00000079 0.00034208 0.00011705]\n",
      " [0.00003868 0.00000206 0.00008297 0.0000016  0.00018069 0.00001086\n",
      "  0.9995213  0.00000009 0.00003366 0.00012808]\n",
      " [0.00019685 0.9918242  0.00021341 0.00039458 0.00033916 0.00054798\n",
      "  0.00035688 0.00051078 0.00374956 0.0018666 ]\n",
      " [0.05564528 0.00090784 0.00082495 0.00713976 0.00760308 0.86262333\n",
      "  0.00260231 0.00138111 0.0060489  0.05522343]\n",
      " [0.00790913 0.00048591 0.93389869 0.0038134  0.01942508 0.00032778\n",
      "  0.02212515 0.00000356 0.01027799 0.0017333 ]\n",
      " [0.00063845 0.0003333  0.00128292 0.00107153 0.93858645 0.0018434\n",
      "  0.0032592  0.00121851 0.00214954 0.0496167 ]\n",
      " [0.43596494 0.00004915 0.00156593 0.00340267 0.00107433 0.00450284\n",
      "  0.0319609  0.00041543 0.24995551 0.27110829]\n",
      " [0.00046979 0.00038686 0.00009635 0.98641214 0.00001508 0.00212069\n",
      "  0.00004096 0.00039035 0.00356418 0.0065036 ]\n",
      " [0.00547176 0.20441531 0.00346565 0.09044877 0.00457438 0.05939836\n",
      "  0.00084739 0.00215071 0.59250549 0.03672218]] (7.161 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 100 into graphs/01.1.mnist.deep.with.estimator/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.2677229046821594.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x114f273c8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": train_data},\n",
    "    y=train_labels,\n",
    "    batch_size=32,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "\n",
    "mnist_classifier.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=100,\n",
    "    hooks=[logging_hook])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-10-01-11:51:56\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from graphs/01.1.mnist.deep.with.estimator/model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-10-01-11:52:09\n",
      "INFO:tensorflow:Saving dict for global step 100: accuracy = 0.9188, global_step = 100, loss = 0.27268216\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100: graphs/01.1.mnist.deep.with.estimator/model.ckpt-100\n",
      "{'accuracy': 0.9188, 'loss': 0.27268216, 'global_step': 100}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model and print results\n",
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": test_data},\n",
    "    y=test_labels,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n",
    "test_results = mnist_classifier.evaluate(input_fn=test_input_fn)\n",
    "print(test_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
